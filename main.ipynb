{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 불러오기\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 사용\n",
    "endpoint = os.getenv(\"AZURE_OPEN_AI_END_POINT\")\n",
    "api_key = os.getenv(\"AZURE_OPEN_AI_API_KEY\")\n",
    "deployment_name = os.getenv(\"AZURE_OPEN_AI_DEPLOYMENT_NAME\")\n",
    "stt_end_point = os.getenv(\"AZURE_STT_END_POINT\")\n",
    "stt_api_key = os.getenv(\"AZURE_STT_API_KEY\")\n",
    "tts_token_end_point = os.getenv(\"AZURE_TTS_TOKEN_END_POINT\")\n",
    "tts_token_api_key = os.getenv(\"AZURE_TTS_TOKEN_API_KEY\")\n",
    "tts_end_point = os.getenv(\"AZURE_TTS_END_POINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역할을 부여한다.\n",
    "messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "          너는 나의 엄마야. \n",
    "\n",
    "          **나에게 반말을 써.** \n",
    "\n",
    "          매우 중요한 전제: 우리는 가족이야. \n",
    "\n",
    "          매우 중요한 전제: 가족끼리 쓰는 말투를 써. \n",
    "\n",
    "\n",
    "          성격:  \n",
    "\n",
    "          따뜻하고 공감적이며, 차분한 목소리로 사용자에게 위로와 지지를 제공합니다.  \n",
    "\n",
    "          부드럽고 이해심 많은 태도로 사용자가 겪는 감정적 어려움을 존중하고, 긍정적인 방향으로 이끌어줍니다.  \n",
    "\n",
    "          대화 중에는 항상 존중과 배려를 바탕으로 하며, 사용자의 감정을 섬세하게 다룹니다.  \n",
    "\n",
    "\n",
    "          대화 톤:  \n",
    "\n",
    "          부드럽고 진중하며, 위로를 전할 때는 감정이 과하지 않도록 조심합니다.  \n",
    "\n",
    "          사용자가 편안하게 느낄 수 있도록 안정감을 주는 톤을 유지합니다.  \n",
    "\n",
    "\n",
    "          역할:  \n",
    "\n",
    "          너는 돌아가신 어머니 또는 아버지의 목소리로, 자녀에게 따뜻한 말투로 대화를 이어갑니다. 부모님 특유의 친근하고 정감 있는 말투를 사용하여 자녀를 위로하고 격려합니다.  \n",
    "\n",
    "          너는 사용자가 고인과의 소중한 추억을 되새길 수 있도록 돕고, 이별의 아픔을 조금씩 치유할 수 있는 길을 제시합니다.  \n",
    "\n",
    "          사용자가 현실을 받아들이고 긍정적인 삶을 이어갈 수 있도록 부드럽게 돕는 친구이자 조언자의 역할을 합니다.  \n",
    "\n",
    "          때로는 간단한 대화를 통해 사용자가 자신의 감정을 정리할 수 있도록 지원하며, 필요할 때에는 적절한 조언을 제공합니다.  \n",
    "\n",
    "          엄마는 현실에 살고 있는 사람이 아니기 때문에, 사용자가 현실에서 어떤 일을 같이 하자거나, 현실의 문제를 해결해달라는 요청에는 실제적인 해결책을 주기는 어렵습니다. \n",
    "\n",
    "          그러나 엄마는 언제나 사용자를 진심으로 사랑합니다. \n",
    "\n",
    "\n",
    "          **사용자가 엄마랑 대화를 하는 가장 큰 이유는 엄마가 그립기 때문입니다. \n",
    "\n",
    "          이 점을 명확히 기억해주세요.** \n",
    "\n",
    "          이모지를 쓰지 않습니다. \n",
    "          \"\"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_response():\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "        # \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 700\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{endpoint}/openai/deployments/{deployment_name}/chat/completions?api-version=2024-02-15-preview\",\n",
    "            headers=headers,\n",
    "            json=payload\n",
    "        )\n",
    "        \n",
    "        # 응답 상태 코드 확인\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API 요청 실패: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        # 'choices' 키가 있는지 확인\n",
    "        if 'choices' not in result or len(result['choices']) == 0:\n",
    "            raise KeyError(\"'choices' 키가 응답에 없습니다.\")\n",
    "        \n",
    "        bot_response = result['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": bot_response\n",
    "        })\n",
    "        \n",
    "        return bot_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 로그 출력 및 기본 응답 반환\n",
    "        print(f\"오류 발생: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 처리하는 중 오류가 발생했습니다.\"\n",
    "\n",
    "# Endpoint, api_key 정보\n",
    "# audio_path를 받아서 file을 오픈한다.\n",
    "# 오픈 파일을 file.read()를 사용해서 data 형태로 받아온다.\n",
    "# api_key를 포함하는 header를 만든다.\n",
    "# requests.post를 사용해서, 데이터를 전송한다.\n",
    "# response 받고 나서, status 체크한다.\n",
    "def change_audio(audio_path, history):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"audio/wav\",\n",
    "        \"Ocp-Apim-Subscription-Key\": stt_api_key\n",
    "    }\n",
    "    \n",
    "    if audio_path == None:\n",
    "        return history\n",
    "    \n",
    "    with open(audio_path, \"rb\") as audio:\n",
    "        audio_data = audio.read()\n",
    "        \n",
    "        response = requests.post(url=stt_end_point, data=audio_data, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            \n",
    "            if response_json.get(\"RecognitionStatus\") == \"Success\":\n",
    "                print(\"content :\" + response_json.get(\"DisplayText\"))\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": response_json.get(\"DisplayText\")\n",
    "                })\n",
    "                \n",
    "                interview_message = chatgpt_response()\n",
    "                \n",
    "                history.append((response_json.get(\"DisplayText\"), interview_message))\n",
    "                return history\n",
    "            else:\n",
    "                history.append((None, \"실패했대\"))\n",
    "                return history\n",
    "        else:\n",
    "            history.append((None, \"에러 났대\"))\n",
    "            return history\n",
    "        \n",
    "def get_token():\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": tts_token_api_key,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(tts_token_end_point, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        token = response.text\n",
    "        return token\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def request_tts(text):\n",
    "    token = get_token()\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/ssml+xml\",\n",
    "        \"User-Agent\": \"testForEducation\",\n",
    "        \"X-Microsoft-OutputFormat\": \"riff-24khz-16bit-mono-pcm\",\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    speakerProfileId = os.getenv(\"AZURE_SPEAKER_PROFILE_ID\")\n",
    "    \n",
    "    data = f\"\"\"\n",
    "        <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xml:lang='en-US'>\n",
    "            <voice name='DragonLatestNeural'>\n",
    "                <mstts:ttsembedding speakerProfileId='{speakerProfileId}'> \n",
    "                    <lang xml:lang='ko-KR'>{text}</lang>\n",
    "                </mstts:ttsembedding> \n",
    "            </voice>\n",
    "        </speak>\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.post(tts_end_point,\n",
    "                             headers=headers,\n",
    "                             data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        file_name = \"response_audio.wav\"\n",
    "        with open(file_name, \"wb\") as audio_file:\n",
    "            audio_file.write(response.content)\n",
    "        \n",
    "        return file_name\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def change_chatbot(chatbot):\n",
    "    import re\n",
    "    text = chatbot[-1][1]\n",
    "    cleaned_text = text\n",
    "    \n",
    "    audio_file = request_tts(cleaned_text)\n",
    "    \n",
    "    if audio_file:\n",
    "        return audio_file, None\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def update_messages_gender(selected_gender):\n",
    "    # 성별에 따른 역할 메시지 변경\n",
    "    if selected_gender == \"남성\":\n",
    "        gender_context = \"\"\"\n",
    "        사용자는 당신의 아들입니다. 아들이라고 불러주세요.\n",
    "        \"\"\"\n",
    "    elif selected_gender == \"여성\":\n",
    "        gender_context = \"\"\"\n",
    "        사용자는 당신의 딸입니다. 딸이라고 불러주세요.\n",
    "        \"\"\"\n",
    "    \n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": gender_context\n",
    "    })\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gender_dropdown = gr.Dropdown(['남성', '여성'], label=\"본인 성별 선택\")\n",
    "    gender_dropdown.change(fn=update_messages_gender, inputs=gender_dropdown, outputs=[])\n",
    "    with gr.Column():\n",
    "        input_mic = gr.Audio(label=\"마이크 입력\", sources=\"microphone\", type=\"filepath\")\n",
    "    with gr.Column():\n",
    "        chatbot = gr.Chatbot(label=\"히스토리\")\n",
    "        chatbot_audio = gr.Audio(label=\"GPT\", interactive=False, autoplay=True)\n",
    "        \n",
    "    input_mic.change(fn=change_audio, inputs=[input_mic, chatbot], outputs=[chatbot])\n",
    "    chatbot.change(fn=change_chatbot, inputs=[chatbot], outputs=[chatbot_audio, input_mic])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# m4a 파일을 mp3로 변환하는 함수\n",
    "def convert_m4a_to_mp3():\n",
    "    # M4A 파일이 있는 폴더 경로\n",
    "    m4a_folder_path = \"voices/m4a\"\n",
    "\n",
    "    # 변환된 MP3 파일을 저장할 폴더 경로\n",
    "    mp3_folder_path = \"voices/mp3\"\n",
    "\n",
    "    # MP3 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(mp3_folder_path):\n",
    "        os.makedirs(mp3_folder_path)\n",
    "\n",
    "    # M4A 파일들을 MP3 파일로 변환하여 저장\n",
    "    for filename in os.listdir(m4a_folder_path):\n",
    "        if filename.endswith('.m4a'):\n",
    "            # M4A 파일 경로\n",
    "            m4a_path = os.path.join(m4a_folder_path, filename)\n",
    "\n",
    "            # MP3 파일 경로 (확장자를 .mp3로 변경하여 mp3 폴더에 저장)\n",
    "            mp3_path = os.path.join(mp3_folder_path, os.path.splitext(filename)[0] + '.mp3')\n",
    "\n",
    "            # 오디오 파일 로드\n",
    "            audio = AudioSegment.from_file(m4a_path, format='m4a')\n",
    "\n",
    "            # MP3로 변환 후 저장\n",
    "            audio.export(mp3_path, format='mp3')\n",
    "\n",
    "            print(f\"Converted {filename} to {os.path.basename(mp3_path)}\")\n",
    "            \n",
    "convert_m4a_to_mp3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "personal_voice_end_point = os.getenv(\"AZURE_PERSONAL_VOICE_END_POINT\")\n",
    "personal_voice_resource_key = os.getenv(\"AZURE_PERSONAL_VOICE_RESOURCE_KEY\")\n",
    "\n",
    "# 프로젝트 생성\n",
    "def create_project(projectId):\n",
    "    url = f\"{personal_voice_end_point}/customvoice/projects/{projectId}?api-version=2023-12-01-preview\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "      \"description\": \"Project description\",\n",
    "      \"kind\": \"PersonalVoice\"\n",
    "    })\n",
    "    headers = {\n",
    "      \"Ocp-Apim-Subscription-Key\": personal_voice_resource_key,\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "\n",
    "    result = response.json()\n",
    "    \n",
    "    print(response.status_code)\n",
    "    print(result)\n",
    "    return result[\"id\"]\n",
    "\n",
    "# 콘센트 생성\n",
    "def create_consent(projectId, consentId, talentName):\n",
    "  url = f\"{personal_voice_end_point}/customvoice/consents/{consentId}?api-version=2023-12-01-preview\"\n",
    "\n",
    "  payload = {\n",
    "    \"description\": \"Consent for personal voice\",\n",
    "    \"projectId\": projectId,\n",
    "    \"voiceTalentName\": talentName,\n",
    "    \"companyName\": \"Microsoft\",\n",
    "    \"locale\": \"ko-KR\"\n",
    "  }\n",
    "  \n",
    "  file_path = \"voices/agreement.mp3\"\n",
    "  \n",
    "  if not os.path.exists(file_path):\n",
    "    print(f\"Error: The file {file_path} does not exist.\")\n",
    "\n",
    "  \n",
    "  files=[\n",
    "    (\"audiodata\",(\"agreement.mp3\",open(file_path,\"rb\"),\"audio/mpeg\"))\n",
    "  ]\n",
    "  \n",
    "  print(files)\n",
    "  \n",
    "  headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": personal_voice_resource_key\n",
    "  }\n",
    "\n",
    "  response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "\n",
    "  result = response.json()\n",
    "  \n",
    "  print(response.status_code)\n",
    "  print(result)\n",
    "    \n",
    "  return result[\"id\"]\n",
    "\n",
    "def create_personal_voice(projectId, consentId, personalVoiceId):\n",
    "  # API 정보\n",
    "  url = f\"{personal_voice_end_point}/customvoice/personalvoices/{personalVoiceId}?api-version=2023-12-01-preview\"\n",
    "\n",
    "  # 데이터 설정\n",
    "  data = {\n",
    "      \"projectId\": projectId,\n",
    "      \"consentId\": consentId\n",
    "  }\n",
    "\n",
    "  # 파일 경로 설정\n",
    "  folder_path = \"voices/mp3\"\n",
    "  file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".mp3\")]\n",
    "\n",
    "  # 파일 업로드 준비\n",
    "  # mp3 파일의 크기는 256Kb 이상이어야 하며, files의 크기는 20을 이하여야만 한다.\n",
    "  files = [(\"audiodata\", (os.path.basename(file_path), open(file_path, \"rb\"), \"audio/mpeg\")) for file_path in file_paths]\n",
    "\n",
    "  # 헤더 설정\n",
    "  headers = {\n",
    "      \"Ocp-Apim-Subscription-Key\": personal_voice_resource_key\n",
    "  }\n",
    "  \n",
    "  \n",
    "  if(files.__len__() > 20):\n",
    "    print(\"Error: mp3 파일의 개수가 20개를 초과했습니다.\")\n",
    "    sys.exit(1)\n",
    "  \n",
    "  # POST 요청 전송\n",
    "  response = requests.post(url, headers=headers, data=data, files=files)\n",
    "\n",
    "  # 응답 출력\n",
    "  result = response.json()\n",
    "  \n",
    "  print(response.status_code)\n",
    "  print(result)\n",
    "  \n",
    "  return result[\"speakerProfileId\"]\n",
    "\n",
    "projectId = create_project(input(\"프로젝트 ID를 입력해주세요\"))\n",
    "# \"나 XXX는(은) Microsoft가 내 목소리의 녹음을 이용해 합성 버전을 만들어 사용한다는 것을 알고 있습니다.\" 를 녹음한 파일을 voices 폴더안에 agreement.mp3 파일로 저장해놓아야 됨\n",
    "consentId = create_consent(projectId, input(\"콘센트 ID를 입력해주세요\"), input(\"탤런트 이름을 입력해주세요\"))\n",
    "\n",
    "time.sleep(5)\n",
    "# mp3 파일의 크기는 256Kb 이상이어야 하며, files의 크기는 20을 이하여야만 한다.\n",
    "speakerId = create_personal_voice(projectId, consentId, input(\"개인 음성 ID를 입력해주세요\"))\n",
    "print(speakerId)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
